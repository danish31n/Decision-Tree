{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Q1 What is a Decision Tree, and how does it work?\n",
        "\n",
        "\n",
        "A **Decision Tree** is a popular machine learning algorithm used for classification and regression tasks. It’s a tree-like structure that breaks down decisions into a series of binary or multiple choices, with each \"branch\" representing a decision rule and each \"leaf\" representing an outcome.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        "1. **Root Node**: The tree starts with a root node, which represents the entire dataset. The first decision (or split) is made based on the most important feature of the data.\n",
        "   \n",
        "2. **Splitting**: The data is split into subsets based on feature values. For example, if we are classifying emails as spam or not, the algorithm might first split the data based on the email's length, then on whether it contains certain keywords, and so on.\n",
        "   \n",
        "3. **Decision Nodes**: After the split, new nodes are created for each subset, which represent further splits based on other features. This process continues until a stopping criterion is reached, such as a specified depth, a minimum number of data points in a node, or when no further useful splits can be made.\n",
        "\n",
        "4. **Leaf Nodes**: These are the terminal points of the tree where no further splits occur. Each leaf node contains a class label (for classification tasks) or a value (for regression tasks).\n",
        "\n",
        "5. **Prediction**: To make a prediction for a new sample, we start at the root of the tree and move through the nodes based on the feature values of the sample. The path we take leads us to a leaf node, where we make the final decision.\n",
        "\n",
        "### Key Features of a Decision Tree:\n",
        "- **Easy to understand and interpret**: You can visualize the tree, which makes it intuitive.\n",
        "- **Handles both numerical and categorical data**: It can work with both types of features without needing preprocessing.\n",
        "- **Non-parametric**: It doesn’t make any assumptions about the data distribution.\n",
        "  \n",
        "### Splitting Criteria:\n",
        "- For **classification**, common criteria for splitting include:\n",
        "  - **Gini Impurity**: Measures the \"impurity\" or \"impurity\" of a node.\n",
        "  - **Entropy**: Measures the disorder or randomness.\n",
        "  - **Information Gain**: Measures the effectiveness of a split based on entropy.\n",
        "\n",
        "- For **regression**, splitting is often based on minimizing variance within each subset.\n",
        "\n",
        "### Pros and Cons:\n",
        "**Pros:**\n",
        "- Easy to interpret and visualize.\n",
        "- Handles both numerical and categorical data.\n",
        "- Non-linear relationships can be captured.\n",
        "\n",
        "**Cons:**\n",
        "- **Overfitting**: Decision trees can overfit the training data if the tree is too deep or complex.\n",
        "- **Instability**: Small changes in the data can result in a completely different tree structure.\n",
        "\n",
        "To prevent overfitting, techniques like **pruning** (removing parts of the tree that don't provide significant predictive power) and ensemble methods like **Random Forests** and **Gradient Boosting** are often used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q2 What are impurity measures in Decision Trees?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In decision trees, **impurity measures** are used to determine how well a split (or decision) divides the data into distinct classes. The goal of decision trees is to create nodes that represent homogenous subsets, meaning that each node should contain instances that are as similar as possible. Impurity measures help quantify how mixed or impure the data is in each node, and they guide the algorithm in choosing the best feature and threshold for each split.\n",
        "\n",
        "Here are the most commonly used impurity measures in decision trees:\n",
        "\n",
        "## 1. **Gini Impurity**\n",
        "**Definition**: Gini impurity measures the likelihood of a wrong classification if a random sample is labeled according to the distribution of labels in a node.  \n",
        "**Formula**:\n",
        "\\$\n",
        "Gini(t) = 1 - \\sum_{i=1}^{C} p_i^2\n",
        "\\$\n",
        "\n",
        "\n",
        "where $p_i$ is the proportion of samples in class $i$ at node $t$, and $C$ is the total number of classes.  \n",
        "**Interpretation**: A Gini impurity of 0 means perfect purity (all samples in the node belong to the same class), and a Gini impurity of 0.5 means a completely impure node with equal distribution of classes.\n",
        "\n",
        "**Usage**: Gini impurity is widely used in algorithms like the CART (Classification and Regression Trees) method.\n",
        "\n",
        "## 2. **Entropy**\n",
        "**Definition**: Entropy measures the disorder or unpredictability of the data in a node. It is based on the concept of information theory, specifically the amount of information required to classify an instance.  \n",
        "**Formula**:\n",
        "\\$\n",
        "Entropy(t) = - \\sum_{i=1}^{C} p_i \\log_2(p_i)\n",
        "\\$\n",
        "\n",
        "where $p_i$ is the proportion of samples in class $i$ at node $t$, and $C$ is the total number of classes.  \n",
        "**Interpretation**: A node with zero entropy means perfect purity (only one class), while a node with maximum entropy means a completely mixed node (uniform distribution of classes).  \n",
        "\n",
        "**Usage**: Entropy is the impurity measure used by the ID3 (Iterative Dichotomiser 3) and C4.5 algorithms.\n",
        "\n",
        "## 3. **Classification Error**\n",
        "**Definition**: Classification error measures the misclassification rate at a given node. It represents the proportion of incorrect classifications in a node.  \n",
        "**Formula**:\n",
        "\\$\n",
        "Error(t) = 1 - \\max(p_1, p_2, \\dots, p_C)\n",
        "\\$\n",
        "\n",
        "where $p_i$ is the proportion of samples in class $i$ at node $t$, and $C$ is the number of classes.  \n",
        "\n",
        "**Interpretation**: The classification error is 0 when all samples in a node belong to the same class, and it approaches 1 as the node becomes more mixed.  \n",
        "**Usage**: This is a simpler measure but less commonly used compared to Gini or entropy, as it doesn't take into account the distribution of the classes beyond just the most frequent class.\n",
        "\n",
        "## How Decision Trees Use Impurity Measures\n",
        "In a decision tree, at each node, the algorithm evaluates potential splits (features and thresholds) by calculating the impurity of the resulting child nodes. The goal is to choose the split that minimizes the impurity, leading to more homogeneous nodes. The process is recursive, continuing until the data in the nodes is sufficiently pure, or until a stopping criterion (like maximum depth or minimum samples per leaf) is met.\n",
        "\n",
        "- **Minimizing Impurity**: A good split will reduce the impurity in child nodes compared to the parent node.\n",
        "- **Best Split**: The feature and threshold that results in the largest reduction in impurity are chosen for each split.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q3 What is the mathematical formula for Gini Impurity?\n",
        "\n",
        "\n",
        "The **mathematical formula for Gini Impurity** is as follows:\n",
        "\n",
        "\\$\n",
        "Gini(t) = 1 - \\sum_{i=1}^{C} p_i^2\n",
        "\\$\n",
        "\n",
        "Where:\n",
        "- $t$ represents a node (or subset) in the decision tree.\n",
        "- $C$ is the total number of classes.\n",
        "- $p_i$ is the proportion of samples belonging to class $i$ in node $t$.\n",
        "\n",
        "### Key Points:\n",
        "- **Gini Impurity = 0**: The node is pure, meaning all samples belong to the same class.\n",
        "- **Gini Impurity > 0**: The node is impure, meaning there is a mix of different classes.\n",
        "- **Gini Impurity = 0.5**: The node is maximally impure, meaning the classes are evenly distributed.\n",
        "\n",
        "\n",
        "### Explanation:\n",
        "- The term $p_i^2$ represents the squared proportion of samples in the node that belong to class $i$.\n",
        "- Summing $p_i^2$ over all classes gives the total \"impurity\" for that node, and subtracting this sum from 1 gives the Gini impurity for the node.\n",
        "  \n",
        "\n",
        "### Example:\n",
        "If a node has 100 samples and they are split into 3 classes with the following distribution:\n",
        "- 40 samples from class 1\n",
        "- 30 samples from class 2\n",
        "- 30 samples from class 3\n",
        "\n",
        "The Gini impurity would be calculated as:\n",
        "\n",
        "\\$\n",
        "p_1 = \\frac{40}{100} = 0.4, \\quad p_2 = \\frac{30}{100} = 0.3, \\quad p_3 = \\frac{30}{100} = 0.3\n",
        "\\$\n",
        "\n",
        "\\$\n",
        "Gini(t) = 1 - (0.4^2 + 0.3^2 + 0.3^2) = 1 - (0.16 + 0.09 + 0.09) = 1 - 0.34 = 0.66\n",
        "\\$\n",
        "\n",
        "So, the Gini impurity for this node would be **0.66**.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q4 What is the mathematical formula for Entropy?\n",
        "\n",
        "\n",
        "The **mathematical formula for Entropy** in the context of decision trees is derived from **information theory** and is used to measure the disorder or uncertainty in a dataset. The formula for entropy at a given node $t$ is:\n",
        "\n",
        "\\$\n",
        "Entropy(t) = - \\sum_{i=1}^{C} p_i \\log_2(p_i)\n",
        "\\$\n",
        "\n",
        "Where:\n",
        "- $t$ represents the node (or subset) in the decision tree.\n",
        "- $C$ is the total number of classes.\n",
        "\n",
        "- $p_i$ is the proportion of samples that belong to class $i$ in node $t$.\n",
        "- The logarithm is taken in base 2, which represents the information content (measured in bits).\n",
        "\n",
        "### Explanation:\n",
        "- $p_i$ represents the probability of a sample belonging to class $i$ in the node.\n",
        "- The term $p_i \\log_2(p_i)$ quantifies the information content (or uncertainty) associated with class $i$.\n",
        "- The sum over all classes gives the total entropy of the node.\n",
        "- The negative sign ensures that entropy is always a non-negative value, as $\\log_2(p_i)$ is negative when $p_i < 1$.\n",
        "\n",
        "### Key Points:\n",
        "- **Entropy = 0**: This means the node is pure (all samples belong to the same class).\n",
        "- **Entropy > 0**: The node is impure, meaning there is uncertainty about which class a sample might belong to.\n",
        "- **Entropy reaches its maximum value when the classes are evenly distributed**, meaning there is maximum uncertainty.\n",
        "\n",
        "### Example:\n",
        "Consider a node with 100 samples, where the class distribution is as follows:\n",
        "- 40 samples from class 1\n",
        "- 30 samples from class 2\n",
        "- 30 samples from class 3\n",
        "\n",
        "The probabilities for each class are:\n",
        "- $p_1 = \\frac{40}{100} = 0.4$\n",
        "- $p_2 = \\frac{30}{100} = 0.3$\n",
        "- $p_3 = \\frac{30}{100} = 0.3$\n",
        "\n",
        "The entropy is calculated as:\n",
        "\n",
        "\\$\n",
        "Entropy(t) = - \\left( 0.4 \\log_2(0.4) + 0.3 \\log_2(0.3) + 0.3 \\log_2(0.3) \\right)\n",
        "\\$\n",
        "\n",
        "Now, calculate the individual logarithms:\n",
        "- $\\log_2(0.4) \\approx -1.322$\n",
        "- $\\log_2(0.3) \\approx -1.737$\n",
        "\n",
        "So:\n",
        "\n",
        "\\$\n",
        "Entropy(t) = - \\left( 0.4 \\times (-1.322) + 0.3 \\times (-1.737) + 0.3 \\times (-1.737) \\right)\n",
        "\\$\n",
        "\n",
        "\\$\n",
        "Entropy(t) = - \\left( -0.5288 + (-0.5211) + (-0.5211) \\right)\n",
        "\\$\n",
        "\n",
        "\\$\n",
        "Entropy(t) = 0.5288 + 0.5211 + 0.5211 = 1.571\n",
        "\\$\n",
        "\n",
        "Thus, the entropy for this node would be **1.571**.\n",
        "\n",
        "### Interpretation:\n",
        "- The entropy value is a measure of impurity or disorder. A higher entropy means more uncertainty or a more mixed class distribution, while lower entropy indicates more homogeneity (purity).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q5 What is Information Gain, and how is it used in Decision Trees?\n",
        "\n",
        "\n",
        "**Information Gain** is a key concept in machine learning, particularly in the construction of **decision trees**. It is used to measure how well a feature (or attribute) splits the data into subsets that are more homogeneous (or pure) with respect to the target variable.\n",
        "\n",
        "### Definition:\n",
        "Information Gain is based on **entropy**, which is a measure of uncertainty or impurity. The idea is to choose the feature that reduces uncertainty the most when splitting the data.\n",
        "\n",
        "### Entropy:\n",
        "Entropy ($H$) measures the uncertainty in a dataset. The entropy for a dataset $S$ is defined as:\n",
        "\n",
        "\\$\n",
        "H(S) = - \\sum_{i=1}^{n} p_i \\log_2(p_i)\n",
        "\\$\n",
        "\n",
        "Where:\n",
        "- $p_i$ is the probability of class $i$ in the dataset $S$,\n",
        "- $n$ is the number of different classes.\n",
        "\n",
        "A dataset with perfect homogeneity (e.g., all samples belong to the same class) has an entropy of 0, while a completely random dataset (e.g., equal distribution of classes) has the maximum entropy.\n",
        "\n",
        "### Information Gain:\n",
        "Information Gain ($IG$) for a feature $A$ is defined as the reduction in entropy achieved by partitioning the dataset based on the feature $A$. It can be calculated as:\n",
        "\n",
        "\\$\n",
        "IG(S, A) = H(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} H(S_v)\n",
        "\\$\n",
        "\n",
        "Where:\n",
        "- $S$ is the original dataset,\n",
        "- $S_v$ is the subset of $S$ where the feature $A$ takes the value $v$,\n",
        "- $|S_v|$ and $|S|$ are the sizes of the subsets $S_v$ and $S$, respectively,\n",
        "- $H(S_v)$ is the entropy of the subset $S_v$.\n",
        "\n",
        "### How Information Gain is Used in Decision Trees:\n",
        "1. **Splitting Criteria**: In decision tree algorithms (like **ID3**), Information Gain is used to select which feature to split on at each step. The algorithm computes the Information Gain for each feature, and the feature with the highest Information Gain is chosen for the next split. This process continues recursively until the tree is fully constructed.\n",
        "\n",
        "2. **Goal**: The goal is to reduce uncertainty as much as possible at each split, leading to increasingly pure subsets of data. A higher Information Gain indicates that the feature provides more useful information about the target variable.\n",
        "\n",
        "3. **Example**:\n",
        "   Suppose you are building a decision tree to predict whether someone buys a product based on features like **age**, **income**, and **location**. At each node, you would compute the Information Gain for each feature (age, income, location), and the feature with the highest Information Gain would be used to split the data at that node.\n",
        "\n",
        "### Intuition:\n",
        "- Information Gain helps to identify the most informative features.\n",
        "- It selects the feature that best \"discriminates\" between different classes.\n",
        "- Features that produce purer (more homogeneous) subsets of data with respect to the target class are preferred.\n",
        "\n",
        "### Advantages of Information Gain:\n",
        "- It's simple and intuitive.\n",
        "- It tends to work well for categorical features, which are common in decision trees.\n",
        "\n",
        "### Drawback:\n",
        "- One issue with Information Gain is that it tends to favor features with more categories or values, as these can split the data into smaller, more homogeneous subsets, leading to higher Information Gain. This is why variations like **Gain Ratio** are sometimes used to address this bias.\n",
        "\n",
        "In summary, Information Gain is a measure of how much uncertainty is reduced by splitting the data on a given feature, and it plays a crucial role in constructing decision trees by helping to choose the best features to split on at each step.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q6 What is the difference between Gini Impurity and Entropy?\n",
        "\n",
        "\n",
        "\n",
        "**Gini Impurity** and **Entropy** are both measures of **impurity** or **uncertainty** used in decision trees for classification tasks, but they have some differences in how they are calculated and how they behave. Here's a detailed comparison:\n",
        "\n",
        "### 1. **Definition**:\n",
        "- **Gini Impurity**:\n",
        "  Gini Impurity is a measure of how often a randomly chosen element from the dataset would be misclassified if it were randomly labeled according to the distribution of labels in the dataset.\n",
        "\n",
        "\n",
        "- **Entropy**:\n",
        "  Entropy is a measure of the uncertainty or disorder in a dataset. It is derived from information theory, specifically designed to quantify the amount of \"information\" needed to classify an element in the dataset.\n",
        "\n",
        "  \n",
        "\n",
        "### 2. **Interpretation**:\n",
        "- **Gini Impurity**: Measures the probability of a **misclassification** of a randomly selected element, i.e., the probability that a sample is incorrectly classified when randomly assigned to one of the classes. It is often seen as a \"cost\" function for classification, where smaller values indicate better purity.\n",
        "  \n",
        "- **Entropy**: Measures the **amount of disorder** or unpredictability in the dataset. A higher entropy means that the class labels are more evenly distributed, and there is more uncertainty about the classification.\n",
        "\n",
        "### 3. **Behavior**:\n",
        "- **Gini Impurity**: Tends to favor **larger splits** that result in more homogeneous nodes but doesn't punish large splits as much as entropy does. It is more \"greedy\" and works faster computationally.\n",
        "  \n",
        "- **Entropy**: Tends to be more sensitive to the distribution of classes. It tends to favor features that split the data in a way that maximizes **information gain** (i.e., reduces uncertainty) the most. Entropy can result in more balanced splits compared to Gini.\n",
        "\n",
        "### 4. **Range of Values**:\n",
        "- **Gini Impurity**: Ranges from 0 to 0.5. For binary classification, Gini Impurity is 0 when the data is perfectly classified and 0.5 when the classes are perfectly mixed.\n",
        "  \n",
        "- **Entropy**: Ranges from 0 to $\\log_2(n)$, where $n$ is the number of classes. For binary classification, the maximum entropy is 1, and the minimum entropy is 0 (perfectly classified).\n",
        "\n",
        "### 5. **Formula Behavior**:\n",
        "- **Gini Impurity**:\n",
        "  - Gini is faster to compute because it only involves squaring the proportions of each class, which is computationally simpler.\n",
        "  - It tends to give slightly different results compared to entropy in the sense that it is more likely to choose a feature that creates larger, less \"balanced\" splits, especially when there are two dominant classes.\n",
        "  \n",
        "- **Entropy**:\n",
        "  - Entropy is computationally more expensive because it involves the logarithm, which requires more processing power.\n",
        "  - It is more sensitive to **class distributions**, and can sometimes result in smaller splits with more pure nodes.\n",
        "\n",
        "### 6. **Preference in Practice**:\n",
        "- **Gini Impurity**: Often preferred when the computation speed is important, because it’s faster to compute and tends to perform similarly to entropy in practice.\n",
        "\n",
        "- **Entropy**: Preferred when the model's interpretability and a more balanced classification split is needed, but it can be slower to compute, especially with a large number of classes.\n",
        "\n",
        "### 7. **Example**:\n",
        "\n",
        "#### Gini Impurity:\n",
        "For a binary classification problem with 2 classes (say, class 0 and class 1), if the dataset has:\n",
        "- 70% of class 0 and 30% of class 1, the Gini Impurity would be:\n",
        "  \n",
        "  \\$\n",
        "  G = 1 - (0.7^2 + 0.3^2) = 1 - (0.49 + 0.09) = 1 - 0.58 = 0.42\n",
        "  \\$\n",
        "\n",
        "#### Entropy:\n",
        "For the same binary classification problem:\n",
        "  \n",
        "    \n",
        "  \\$\n",
        "  H = - (0.7 \\log_2 0.7 + 0.3 \\log_2 0.3) = -(0.7 \\times (-0.514) + 0.3 \\times (-1.737)) \\approx 0.88\n",
        "  \\$\n",
        "\n",
        "  \n",
        "### Key Takeaways:\n",
        "- **Gini Impurity** is simpler and faster to compute but less sensitive to class distribution.\n",
        "- **Entropy** is more sensitive to class distributions and tries to find splits that minimize uncertainty but is computationally more expensive.\n",
        "- Both measures aim to make the data at each node in a decision tree as pure as possible, but the way they approach the task differs in terms of calculation and preference for certain types of splits.\n",
        "\n",
        "In practice, the difference between Gini Impurity and Entropy is often subtle, and both tend to give similar results in many cases. However, Gini is typically favored in decision tree implementations (e.g., in **CART** algorithm) due to its computational efficiency.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q7 What is the mathematical explanation behind Decision Trees?\n",
        "\n",
        "\n",
        "\n",
        "A **Decision Tree** is a supervised machine learning algorithm that is used for both classification and regression tasks. The goal of a decision tree is to recursively split the dataset into subsets that are more homogeneous with respect to the target variable by using different features at each decision node.\n",
        "\n",
        "Here is a breakdown of the mathematical principles behind decision trees:\n",
        "\n",
        "\n",
        "### 1. **Basic Structure**:\n",
        "A decision tree consists of:\n",
        "- **Root Node**: Represents the entire dataset or the starting point of the tree.\n",
        "- **Internal Nodes**: Represent decision points based on feature values.\n",
        "- **Leaf Nodes**: Represent the final prediction or class labels (in classification) or continuous values (in regression).\n",
        "- **Edges**: Connect the nodes and represent the outcome of a decision based on the feature's value.\n",
        "\n",
        "The objective of a decision tree is to recursively split the data at each node into subsets based on features that result in the most \"homogeneous\" or \"pure\" subsets.\n",
        "\n",
        "\n",
        "\n",
        "### 2. **Splitting Criterion**:\n",
        "The decision tree algorithm recursively partitions the dataset by selecting the feature and threshold value that best divides the data into distinct classes or values. The **splitting criterion** is based on a measure of impurity, such as **Gini Impurity** or **Entropy** (as explained earlier).\n",
        "\n",
        "At each internal node, the tree needs to decide which feature and what threshold to use to split the dataset. This decision is made by choosing the feature and threshold that minimize impurity.\n",
        "\n",
        "#### **Gini Impurity (for classification)**:\n",
        "At each node, the Gini Impurity is calculated to measure the \"impurity\" or \"purity\" of the dataset.\n",
        "\n",
        "For a dataset $S$ with $n$ classes, the Gini Impurity is given by:\n",
        "\n",
        "$$\n",
        "G(S) = 1 - \\sum_{i=1}^{n} p_i^2\n",
        "$$\n",
        "\n",
        "Where $p_i$ is the proportion of class $i$ in the dataset $S$.\n",
        "\n",
        "When the dataset is split into two subsets, $S_1$ and $S_2$, the **weighted average Gini Impurity** is calculated:\n",
        "\n",
        "$$\n",
        "G_{\\text{split}} = \\frac{|S_1|}{|S|} G(S_1) + \\frac{|S_2|}{|S|} G(S_2)\n",
        "$$\n",
        "\n",
        "The goal is to minimize the Gini Impurity at each node, i.e., we want the Gini Impurity of the split dataset to be as low as possible.\n",
        "\n",
        "#### **Entropy (for classification)**:\n",
        "Similarly, Entropy measures the uncertainty of the class distribution. The Entropy of a dataset $S$ is:\n",
        "\n",
        "$$\n",
        "H(S) = - \\sum_{i=1}^{n} p_i \\log_2 p_i\n",
        "$$\n",
        "\n",
        "Where $p_i$ is the proportion of instances in class $i$.\n",
        "\n",
        "When splitting into two subsets $S_1$ and $S_2$, the **Information Gain** is used to choose the best split:\n",
        "\n",
        "$$\n",
        "IG(S, A) = H(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} H(S_v)\n",
        "$$\n",
        "\n",
        "Here, $A$ is the feature being split on, and $S_v$ is the subset of $S$ where feature $A$ takes the value $v$.\n",
        "\n",
        "The goal is to maximize the Information Gain, which corresponds to reducing uncertainty (or entropy).\n",
        "\n",
        "\n",
        "\n",
        "### 3. **Recursive Splitting (Top-Down Approach)**:\n",
        "At each internal node, the decision tree algorithm performs the following steps:\n",
        "1. **Select the best feature**: Calculate the impurity (Gini or Entropy) for all features and select the one with the best split (i.e., the one that minimizes impurity or maximizes Information Gain).\n",
        "2. **Split the dataset**: Based on the best feature and threshold, split the dataset into subsets.\n",
        "3. **Repeat recursively**: Apply the same procedure to each of the subsets, splitting until certain stopping conditions are met (e.g., maximum depth, minimum number of samples at a node, or purity threshold).\n",
        "\n",
        "This process results in a tree structure where each node represents a decision based on a feature, and the leaves represent the final classification or regression result.\n",
        "\n",
        "\n",
        "\n",
        "### 4. **Stopping Criteria**:\n",
        "The tree-building process stops under certain conditions to avoid overfitting. Common stopping criteria include:\n",
        "- **Maximum depth of the tree**: Limit the depth of the tree to avoid excessive branching.\n",
        "- **Minimum samples per leaf**: Set a threshold for the minimum number of samples required in a leaf node.\n",
        "- **Minimum Information Gain**: Stop splitting if the Information Gain from a potential split is smaller than a predefined threshold.\n",
        "- **Maximum number of nodes**: Limit the total number of nodes to prevent the tree from growing too large.\n",
        "\n",
        "\n",
        "\n",
        "### 5. **Prediction**:\n",
        "Once the tree is built, predicting the target for a new sample involves:\n",
        "- Starting at the root of the tree.\n",
        "- Moving down the tree by following the decisions (based on feature values) at each internal node.\n",
        "- Reaching a leaf node, which contains the predicted class or value.\n",
        "\n",
        "For **classification** problems, the class label at a leaf is typically the most frequent class in the leaf node.\n",
        "For **regression** problems, the prediction is typically the average of the target values in the leaf node.\n",
        "\n",
        "\n",
        "\n",
        "### 6. **Mathematical Example (Binary Classification)**:\n",
        "Suppose we are building a decision tree to predict whether someone buys a product based on age and income. The dataset contains the following columns:\n",
        "- **Age**: Age of the individual.\n",
        "- **Income**: Income of the individual.\n",
        "- **Buy**: Whether the individual buys the product (1 for Yes, 0 for No).\n",
        "\n",
        "The algorithm might compute the Gini Impurity or Entropy for different splits, for example:\n",
        "\n",
        "- **Split 1**: Age < 30\n",
        "- **Split 2**: Income > 50k\n",
        "\n",
        "For each split, the algorithm calculates the impurity (e.g., Gini Impurity or Entropy) of the resulting subsets. The feature and threshold that result in the lowest impurity (highest information gain) are chosen. The process continues recursively to build the tree.\n",
        "\n",
        "\n",
        "\n",
        "### 7. **Pruning**:\n",
        "Once the tree is constructed, it may become too complex, potentially leading to overfitting. **Pruning** is the process of removing nodes or branches that add little predictive power, reducing the complexity of the tree and improving generalization. Pruning can be done through techniques like **Cost-Complexity Pruning** or **Reduced Error Pruning**.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q8 What is Pre-Pruning in Decision Trees?\n",
        "\n",
        "\n",
        "Pre-pruning in decision trees refers to the technique of stopping the tree from growing too large by setting a limit during the tree-building process. Essentially, it is a strategy to prevent overfitting by halting the splitting of nodes before the tree fully develops. The goal is to ensure that the tree remains simple and generalizes better to new, unseen data.\n",
        "\n",
        "Some common methods of pre-pruning include:\n",
        "\n",
        "1. **Maximum Depth**: Limiting the depth of the tree ensures that the tree doesn’t grow too deep, thus preventing it from fitting noise or specific patterns in the training data that don't generalize well.\n",
        "\n",
        "2. **Minimum Samples per Split**: This parameter defines the minimum number of samples required to split an internal node. If a split would result in fewer than this number of samples, the split is not made.\n",
        "\n",
        "3. **Minimum Samples per Leaf**: Similar to the above, this restricts the number of samples required in a leaf node. Nodes that would have fewer samples are not split.\n",
        "\n",
        "4. **Maximum Number of Leaf Nodes**: This parameter places a limit on the total number of leaf nodes in the tree. This can prevent the tree from growing excessively.\n",
        "\n",
        "5. **Maximum Features**: It can restrict the number of features considered at each split, which can also help reduce the complexity of the tree.\n",
        "\n",
        "By applying pre-pruning techniques, the decision tree is forced to make simpler decisions during its construction, which can reduce the likelihood of overfitting. However, it is a trade-off—too much pruning can lead to underfitting, where the model fails to capture important patterns in the data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q9 What is Post-Pruning in Decision Trees?\n",
        "\n",
        "\n",
        "**Post-pruning** in decision trees is a technique used to improve the generalization ability of the model by reducing overfitting. Overfitting occurs when the decision tree becomes too complex and fits the noise in the training data rather than capturing the underlying patterns. Post-pruning, also known as **cost-complexity pruning** or **weakening**, helps simplify the model after the tree has been fully grown.\n",
        "\n",
        "Here’s how post-pruning works:\n",
        "\n",
        "1. **Grow the Tree Fully:** First, you build the decision tree without any constraints, allowing it to grow as deep as possible, which may lead to overfitting.\n",
        "\n",
        "2. **Prune the Tree:** After the tree is grown, post-pruning starts by removing (or \"pruning\") branches that have little predictive power or might be contributing to overfitting. Pruning is typically done by removing nodes or subtrees that don't improve the model's performance significantly.\n",
        "\n",
        "3. **Evaluate Performance:** Pruning involves evaluating the impact of removing certain branches on the tree’s overall performance. Usually, a validation set or cross-validation is used to check the performance after pruning.\n",
        "\n",
        "4. **Cost-Complexity Pruning:** One common form of post-pruning is cost-complexity pruning, which adds a penalty for each node removed. This process balances the complexity of the tree (the number of branches) and its accuracy. A parameter (often denoted as **α**) controls the level of pruning: a higher value of **α** leads to more aggressive pruning, resulting in a simpler tree.\n",
        "\n",
        "The key benefit of post-pruning is that it helps prevent overfitting by removing unnecessary parts of the tree that do not contribute much to making predictions. It results in a simpler, more interpretable model that performs better on unseen data.\n",
        "\n",
        "### Example of Post-Pruning Process:\n",
        "1. Build a tree with no pruning.\n",
        "2. Use a validation set to assess the tree's performance.\n",
        "3. Remove branches that do not improve performance significantly (based on some pruning criterion, like accuracy on a validation set).\n",
        "4. Repeat the pruning process and evaluate until the tree performance stabilizes or starts to decline.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q10 What is the difference between Pre-Pruning and Post-Pruning?\n",
        "\n",
        "Pre-pruning and post-pruning are two techniques used to prevent overfitting in decision tree algorithms by controlling the complexity of the tree. They differ mainly in when the pruning happens during the tree construction process.\n",
        "\n",
        "### 1. **Pre-Pruning (Early Stopping)**\n",
        "   - **Definition:** Pre-pruning stops the tree from growing too complex by setting conditions that must be met during the tree construction process. If a node doesn’t meet these conditions, it’s not expanded further.\n",
        "\n",
        "   - **How it works:** While building the tree, the algorithm may decide to halt the growth of the tree at an early stage if certain criteria are met (e.g., if the node has too few samples, or if the improvement in impurity reduction is minimal). This prevents the tree from becoming too large.\n",
        "   - **Criteria examples:**\n",
        "     - Maximum depth of the tree.\n",
        "\n",
        "     - Minimum number of samples required to split a node.\n",
        "     - Minimum impurity decrease required to make a further split.\n",
        "   - **Advantages:**\n",
        "     - It is faster because it limits the size of the tree during construction.\n",
        "\n",
        "     - Helps in controlling the tree complexity from the start.\n",
        "   - **Disadvantages:**\n",
        "     - It may stop the tree from learning enough, leading to underfitting.\n",
        "\n",
        "     - It’s hard to choose the right pruning conditions without cross-validation or tuning.\n",
        "\n",
        "### 2. **Post-Pruning (Cost-Complexity Pruning)**\n",
        "   - **Definition:** Post-pruning, also known as \"cost-complexity pruning,\" involves growing the full tree first and then removing parts of the tree that are not contributing to its predictive accuracy.\n",
        "   - **How it works:** After the tree is fully grown, it is pruned by removing branches (subtrees) that have little importance or lead to overfitting. The idea is to prune the tree backward, starting from the leaves and moving towards the root, based on some pruning criterion (like minimal cost or error).\n",
        "   - **Criteria examples:**\n",
        "     - Reducing the error rate after pruning.\n",
        "     - Minimizing the tree's complexity while maintaining accuracy.\n",
        "   - **Advantages:**\n",
        "     - The tree is allowed to fully explore the data, leading to a better model fit before pruning.\n",
        "     - The pruning is data-driven and typically results in a more optimal tree.\n",
        "   - **Disadvantages:**\n",
        "     - Computationally more expensive because it requires constructing the entire tree first.\n",
        "     - It may result in overfitting if the pruning criteria are not chosen properly.\n",
        "\n",
        "### Key Differences:\n",
        "| Feature            | Pre-Pruning                          | Post-Pruning                         |\n",
        "|--------------------|--------------------------------------|--------------------------------------|\n",
        "| **When pruning happens** | During the tree construction phase. | After the tree is fully grown.      |\n",
        "| **Goal**            | Stop the tree from growing too complex. | Simplify the tree after it is constructed. |\n",
        "| **Efficiency**      | Faster, as the tree is constrained from the beginning. | Slower, as it requires constructing the full tree first. |\n",
        "| **Risk of Overfitting** | Less risk of overfitting, but might lead to underfitting if too many splits are prevented. | More risk of overfitting, but can be pruned back to a good size. |\n",
        "| **Control**         | Limited control over the final structure. | More flexibility in determining the final structure. |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q11 What is a Decision Tree Regressor?\n",
        "\n",
        "A **Decision Tree Regressor** is a type of machine learning algorithm used for **regression tasks**, which involve predicting a continuous value (as opposed to classification tasks where the goal is to predict discrete labels). The Decision Tree Regressor works by recursively splitting the data into subsets based on feature values, ultimately constructing a tree-like structure that can predict numerical values.\n",
        "\n",
        "### Key Features of a Decision Tree Regressor:\n",
        "\n",
        "1. **Structure:**\n",
        "   - The tree is made up of **nodes** and **edges**.\n",
        "     - **Root node**: The starting point, representing the entire dataset.\n",
        "     - **Internal nodes**: These represent decisions or tests on an attribute (feature).\n",
        "\n",
        "     - **Leaf nodes**: These represent the predicted output value (the continuous value).\n",
        "   - Each decision or split at an internal node aims to divide the data into subsets that are as homogeneous as possible with respect to the target value.\n",
        "\n",
        "2. **Splitting Process:**\n",
        "   - At each internal node, the algorithm chooses the best feature and the best split point (value) to minimize the variance (or maximize the information gain) in the resulting subsets.\n",
        "\n",
        "   - Common splitting criteria for regression trees are:\n",
        "     - **Mean Squared Error (MSE):** The algorithm splits the data to minimize the MSE (the average squared difference between the observed and predicted values).\n",
        "     - **Mean Absolute Error (MAE):** Another metric, focusing on minimizing the average absolute error.\n",
        "\n",
        "3. **Prediction:**\n",
        "   - For any new data point, the algorithm follows the tree from the root to a leaf node, applying the same tests at each internal node. The prediction is made by using the average value of the target variable in the leaf node where the data point ends up.\n",
        "\n",
        "4. **Example Use Case:**\n",
        "   - Predicting the price of a house based on features such as the size, number of rooms, location, etc.\n",
        "   - Predicting stock prices, where historical data is used to predict future prices.\n",
        "\n",
        "\n",
        "### Example:\n",
        "Let’s say we have a dataset with the following features:\n",
        "- **Square Footage** (numerical)\n",
        "\n",
        "- **Number of Rooms** (numerical)\n",
        "- **Location** (categorical)\n",
        "\n",
        "And the target variable is **Price** (numerical). The decision tree regressor might learn that:\n",
        "- If the **Square Footage** is greater than 2000 square feet, it predicts a high price.\n",
        "- If the **Location** is near a city center, the price is predicted to be higher, regardless of the square footage.\n",
        "\n",
        "### Hyperparameters:\n",
        "Some key hyperparameters you can tune in a decision tree regressor are:\n",
        "- **max_depth**: The maximum depth of the tree.\n",
        "- **min_samples_split**: The minimum number of samples required to split an internal node.\n",
        "\n",
        "- **min_samples_leaf**: The minimum number of samples required to be at a leaf node.\n",
        "\n",
        "- **max_features**: The number of features to consider when looking for the best split.\n",
        "  \n",
        "### In Practice:\n",
        "Decision Tree Regressor is often used as a baseline model due to its simplicity and interpretability. However, to improve its performance, it’s often combined with ensemble methods like **Random Forests** or **Gradient Boosting**, which help reduce overfitting and improve accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q12 What are the advantages and disadvantages of Decision Trees?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1. **Easy to Understand and Interpret:**\n",
        "   - Decision trees are easy to visualize and interpret, even by non-experts. The structure is like a flowchart, making it intuitive to follow the decision-making process.\n",
        "   \n",
        "2. **No Need for Feature Scaling:**\n",
        "   - Unlike algorithms like SVM or KNN, decision trees don’t require feature scaling (like normalization or standardization). They work well with raw data.\n",
        "   \n",
        "3. **Handles Both Numerical and Categorical Data:**\n",
        "   - Decision trees can handle both continuous (numerical) and discrete (categorical) variables, making them versatile.\n",
        "   \n",
        "4. **Non-Linear Relationships:**\n",
        "   - They can model complex, non-linear relationships between features without the need for transformation.\n",
        "\n",
        "5. **Modeling Missing Values:**\n",
        "   - Decision trees can handle missing data and can still make predictions by finding the best split based on available data.\n",
        "\n",
        "6. **No Assumption about Data Distribution:**\n",
        "   - Unlike linear models, decision trees don’t make assumptions about the underlying distribution of the data, which makes them more flexible for various data types.\n",
        "\n",
        "\n",
        "\n",
        "**Disadvantages of Decision Trees:**\n",
        "\n",
        "1. **Overfitting:**\n",
        "   - Decision trees tend to overfit, especially with deep trees. They can create overly complex models that capture noise rather than the underlying data patterns.\n",
        "\n",
        "2. **Instability:**\n",
        "   - Small changes in the data can lead to different splits in the tree, making decision trees sensitive to variations in the training data.\n",
        "\n",
        "3. **Bias Toward Dominant Features:**\n",
        "   - If one feature is much more significant than others, decision trees might heavily rely on that feature and ignore others, leading to biased models.\n",
        "\n",
        "4. **Difficulty with High Dimensionality:**\n",
        "   - Decision trees might perform poorly when dealing with high-dimensional data (lots of features), especially if there are many irrelevant features, as they tend to overfit in such cases.\n",
        "\n",
        "5. **Lack of Smoothness:**\n",
        "   - The decision boundary created by decision trees is axis-aligned (parallel to the feature axes), which may not be optimal for some problems, particularly those with complex relationships that require more flexible boundaries.\n",
        "\n",
        "6. **Computational Cost for Large Datasets:**\n",
        "   - For large datasets with many features, building a decision tree can become computationally expensive and time-consuming.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q13 How does a Decision Tree handle missing values?\n",
        "\n",
        "\n",
        "A **Decision Tree** can handle missing values in several ways, depending on the specific implementation or algorithm. Here are the common strategies that Decision Trees use to manage missing data:\n",
        "\n",
        "### 1. **Surrogate Splits**:\n",
        "   Some Decision Tree algorithms (like CART) use **surrogate splits** to handle missing values. Surrogate splits are backup rules that help the tree decide the best split when the primary feature value is missing. The surrogate is the feature that closely mimics the effect of the primary feature split. If the primary feature is missing, the surrogate is used to make the decision.\n",
        "\n",
        "### 2. **Ignoring the Missing Values**:\n",
        "   When a Decision Tree encounters a missing value in a feature for a particular instance, it can simply **ignore that instance** during the split. In this case, the algorithm will look at the remaining data for that particular feature to make the decision. This method can sometimes result in lower model performance, especially when missing values are not randomly distributed.\n",
        "\n",
        "### 3. **Imputation (Before Training)**:\n",
        "   Another approach is to **impute** the missing values **before** training the model. Imputation can be done in several ways, such as:\n",
        "   - **Mean/Median Imputation**: For continuous variables, missing values are replaced with the mean or median of the feature.\n",
        "\n",
        "   - **Mode Imputation**: For categorical variables, missing values are replaced with the most frequent value (mode) of the feature.\n",
        "   - **Predictive Imputation**: Missing values can be predicted using other machine learning models (like regression or k-nearest neighbors) that estimate the missing values based on the other available features.\n",
        "\n",
        "### 4. **Assigning a \"Missing\" Category**:\n",
        "   For categorical features, one simple approach is to treat missing values as a **separate category**. This would mean that missing values are explicitly handled as their own category, making the tree learn splits that explicitly include missing data.\n",
        "\n",
        "### 5. **Probabilistic Handling**:\n",
        "   Some advanced Decision Tree algorithms might use a probabilistic method to **assign a probability distribution** over the possible outcomes for missing values. Instead of deciding on a single split, they assign probabilities to different branches based on the distribution of data for that feature.\n",
        "\n",
        "### 6. **Gini Index / Entropy Adjustment**:\n",
        "   In some cases, the tree algorithm adjusts the **splitting criteria** (like the Gini index or entropy) to handle the missing values. The decision tree might modify its calculations to account for instances with missing data, weighting them appropriately when calculating impurity measures.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q14 How does a Decision Tree handle categorical features?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A **Decision Tree** handles categorical features differently than continuous features because categorical variables represent distinct, non-ordered values (e.g., \"red,\" \"blue,\" \"green\" or \"dog,\" \"cat\"). Here's how a Decision Tree typically handles categorical features:\n",
        "\n",
        "### 1. **Splitting Based on Categories**:\n",
        "   For categorical features, the tree makes decisions by splitting the data based on categories or groups. It determines which categories or combinations of categories best separate the data into the most homogenous subsets.\n",
        "\n",
        "   - **Binary Splits**: In many Decision Tree algorithms, especially those based on the **CART** (Classification and Regression Trees) algorithm, a categorical feature is often split into **two groups** (or subsets) based on a particular condition. For example, if the categorical feature has values like “red,” “blue,” and “green,” the tree might split the data into two sets, such as \"red\" vs. \"blue and green.\"\n",
        "   \n",
        "   - **Multi-way Splits**: In some algorithms, the tree can create **multi-way splits** based on all possible combinations of categories in a categorical feature. For instance, if a categorical feature has values “red,” “blue,” and “green,” the tree might consider all three categories in the split.\n",
        "\n",
        "### 2. **Using Gini Index or Entropy**:\n",
        "   During the splitting process, the tree uses criteria like **Gini Impurity** or **Entropy** to measure how well each potential split divides the data. The goal is to find the split that minimizes impurity or maximizes information gain (depending on the criteria used).\n",
        "\n",
        "   - **Gini Index**: The tree calculates the Gini Index for each potential split, whether it's based on a categorical or continuous feature. It evaluates how well the split divides the dataset into homogenous subsets (with respect to the target variable).\n",
        "   \n",
        "   - **Entropy**: Similarly, entropy measures how “pure” each group of data is. The tree chooses the split that results in the greatest information gain (or the lowest entropy).\n",
        "\n",
        "### 3. **Handling Multiple Categories**:\n",
        "   If a categorical feature has many possible values (e.g., a feature like \"country\" with many different countries), the Decision Tree might use the **best split** based on those categories. For instance:\n",
        "   \n",
        "   - If the tree considers all possible combinations of categories, it can decide to split data into smaller, more homogeneous groups based on combinations like \"USA\" vs \"Rest of the world\" or \"North America\" vs \"Europe, Asia.\"\n",
        "\n",
        "### 4. **One-Hot Encoding (Preprocessing)**:\n",
        "   Before training the Decision Tree, categorical features can be transformed using techniques like **One-Hot Encoding** or **Label Encoding**.\n",
        "   \n",
        "   - **One-Hot Encoding**: Each category is transformed into a binary vector. This is useful when there is no inherent order among the categories (i.e., the feature is nominal). For example, a feature like \"color\" with categories [\"red\", \"green\", \"blue\"] would be transformed into three binary features: \"is_red\", \"is_green\", and \"is_blue.\" The tree would then handle these binary features like continuous ones, determining the best split based on each feature.\n",
        "   \n",
        "   - **Label Encoding**: Each category is mapped to an integer value. For instance, “red” might become 0, “green” becomes 1, and “blue” becomes 2. However, this method might introduce an unintended ordinal relationship (i.e., it could suggest that \"green\" is between \"red\" and \"blue\"), which could be problematic if the categorical variable is nominal.\n",
        "\n",
        "### 5. **Missing Categorical Data**:\n",
        "   If a categorical feature contains missing values, Decision Trees can handle the missing data by using strategies such as:\n",
        "   \n",
        "   - **Imputation**: Missing values can be replaced with the most frequent category (mode) or inferred using other methods before the tree is built.\n",
        "   \n",
        "   - **Surrogate Splits**: If an important feature value is missing during the decision-making process, the tree might use a **surrogate split**, which is a backup decision rule that mimics the original rule for non-missing data.\n",
        "\n",
        "### 6. **Handling Ordinal Categorical Features**:\n",
        "   If a categorical feature has an **inherent order** (e.g., \"low\", \"medium\", \"high\"), the Decision Tree might treat it similarly to a continuous feature. This means the tree might create splits like \"low\" vs. \"medium and high.\" In such cases, some tree algorithms can make better use of the ordinal nature of the feature.\n",
        "\n",
        "### 7. **Advantages of Decision Trees for Categorical Features**:\n",
        "   - **Non-linear**: Decision Trees do not assume linearity in data, making them very flexible for handling categorical features.\n",
        "   - **No need for scaling**: Unlike many other machine learning algorithms, Decision Trees do not require categorical features to be normalized or standardized.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Q15 What are some real-world applications of Decision Trees?\n",
        "\n",
        "\n",
        "Decision trees are widely used in various real-world applications due to their simplicity, interpretability, and effectiveness in solving complex problems. Here are some key areas where decision trees are applied:\n",
        "\n",
        "### 1. **Medical Diagnosis**\n",
        "   - **Example**: Decision trees can be used to assist in diagnosing diseases based on patient symptoms, medical history, and test results. A decision tree could classify whether a patient has a particular condition (like diabetes or heart disease) based on their age, blood pressure, cholesterol levels, etc.\n",
        "\n",
        "### 2. **Credit Scoring**\n",
        "   - **Example**: Financial institutions use decision trees to assess the creditworthiness of individuals. By analyzing factors such as income, credit history, and current debt, a decision tree can help determine whether to approve a loan or credit application.\n",
        "\n",
        "### 3. **Customer Segmentation**\n",
        "   - **Example**: In marketing, decision trees are often used to segment customers based on their purchasing behavior, preferences, or demographics. This allows businesses to tailor their marketing strategies to different customer groups more effectively.\n",
        "\n",
        "### 4. **Fraud Detection**\n",
        "   - **Example**: In banking or insurance, decision trees can be employed to identify fraudulent activities by analyzing transaction data, patterns, and anomalies. For instance, they might detect unusual spending behaviors that deviate from the norm and flag them for further investigation.\n",
        "\n",
        "### 5. **Sales and Lead Qualification**\n",
        "   - **Example**: Decision trees can help sales teams prioritize leads by assessing factors like how likely a lead is to convert into a sale. Variables like company size, industry, and engagement level with marketing materials can guide sales teams in focusing their efforts more effectively.\n",
        "\n",
        "### 6. **Supply Chain and Inventory Management**\n",
        "   - **Example**: Decision trees can be used to forecast demand for products, helping businesses optimize their inventory levels and supply chain operations. By considering historical data, seasonal trends, and sales patterns, decision trees can help predict future inventory needs.\n",
        "\n",
        "### 7. **Image Classification and Object Recognition**\n",
        "   - **Example**: In computer vision, decision trees are sometimes used for classifying objects within images, such as identifying different types of animals in photos or detecting specific shapes in satellite imagery.\n",
        "\n",
        "### 8. **Risk Assessment**\n",
        "   - **Example**: Decision trees are useful in assessing risk in various industries, such as insurance, where they help determine premiums or coverage options based on risk factors like the age of the insured, type of property, or location.\n",
        "\n",
        "### 9. **Churn Prediction**\n",
        "   - **Example**: In telecom and subscription-based services (like Netflix or Spotify), decision trees can predict customer churn, identifying which customers are likely to cancel their service based on factors like usage patterns, contract length, and customer support interactions.\n",
        "\n",
        "### 10. **Product Recommendations**\n",
        "   - **Example**: E-commerce platforms like Amazon and Netflix use decision trees (along with other machine learning techniques) to recommend products or movies based on user behavior, past purchases, ratings, and preferences.\n",
        "\n",
        "### 11. **Human Resources and Employee Retention**\n",
        "   - **Example**: HR departments use decision trees to predict employee retention by analyzing factors such as tenure, job satisfaction, compensation, and work-life balance. This helps in identifying employees at risk of leaving and implementing retention strategies.\n",
        "\n",
        "### 12. **Energy Consumption Forecasting**\n",
        "   - **Example**: Decision trees can be applied to predict energy consumption patterns for homes or businesses based on factors like weather, time of day, and past energy usage. This helps utility companies optimize energy distribution.\n",
        "\n",
        "### 13. **Game Strategy and AI in Gaming**\n",
        "   - **Example**: In strategic games or AI-driven gaming, decision trees are used to predict the best possible moves for the game characters based on the current state of the game, maximizing the chances of winning or achieving objectives.\n",
        "\n",
        "### 14. **Manufacturing and Quality Control**\n",
        "   - **Example**: In manufacturing, decision trees can help detect potential faults or predict failures in machinery by analyzing various sensor data like temperature, pressure, and operating conditions.\n",
        "\n",
        "In all these applications, decision trees offer an easy-to-understand model for decision-making that can be visualized and interpreted, which makes them particularly useful in fields where transparency and accountability are critical.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ucQ1XMv_GgdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#16 Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "data\n",
        "df = pd.DataFrame(data.data, columns= data.feature_names)\n",
        "\n",
        "df['target'] = data.target\n",
        "\n",
        "x = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "# Train Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.30, random_state= 1)\n",
        "\n",
        "#Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "#Model Training\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train, y_train)\n",
        "\n",
        "#Prediction\n",
        "y_pred = dt.predict(x_test)\n",
        "\n",
        "# Model evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy score: \",accuracy_score(y_test,y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpptVF-ESzOt",
        "outputId": "6555a787-ff90-424f-afd0-2d3f13f26860"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:  0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#17 Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "data\n",
        "df = pd.DataFrame(data.data, columns= data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.20, random_state= 1)\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(criterion='gini', random_state= 1)\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "for feature, important in zip(data.feature_names, model.feature_importances_):\n",
        "  print(f\"{feature} : {important}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CcPiuSiaZBm",
        "outputId": "dcf4dfe2-2a1d-4e35-b827-089a5124c710"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) : 0.007520367662419047\n",
            "sepal width (cm) : 0.01880091915604763\n",
            "petal length (cm) : 0.07584565922951901\n",
            "petal width (cm) : 0.8978330539520143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#18 Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "data = load_wine()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.30, random_state= 1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(criterion='entropy')\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "ypred = clf.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy score: \",accuracy_score(y_test,ypred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g95zIDXKO8a6",
        "outputId": "baeb1b98-e60e-437f-a54f-e892ceaa4d7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:  0.9259259259259259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#19 Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE).\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.33, random_state= 1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "dt = DecisionTreeRegressor()\n",
        "dt.fit(x_train,y_train)\n",
        "\n",
        "y_pred = dt.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Mean Squared Error(MSE): \",mean_squared_error(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeSOg6RWQvlA",
        "outputId": "333bef02-4298-4a28-f0d2-48f784be1fc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error(MSE):  0.5512544124029359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20 Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.33, random_state= 1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train,y_train)\n",
        "\n",
        "y_pred = dt.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print('\\n')\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Visualize the decision tree\n",
        "dot_data = export_graphviz(dt, out_file=None,\n",
        "                           feature_names=data.feature_names,\n",
        "                           class_names=data.target_names,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "\n",
        "graph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "e3EtYv5gSmAn",
        "outputId": "49cfb1bc-a82d-4e77-920c-eeb588a2c103"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"612pt\" height=\"552pt\"\n viewBox=\"0.00 0.00 612.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-548 608,-548 608,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f9f6fe\" stroke=\"black\" d=\"M294.5,-544C294.5,-544 166.5,-544 166.5,-544 160.5,-544 154.5,-538 154.5,-532 154.5,-532 154.5,-473 154.5,-473 154.5,-467 160.5,-461 166.5,-461 166.5,-461 294.5,-461 294.5,-461 300.5,-461 306.5,-467 306.5,-473 306.5,-473 306.5,-532 306.5,-532 306.5,-538 300.5,-544 294.5,-544\"/>\n<text text-anchor=\"start\" x=\"162.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 2.6</text>\n<text text-anchor=\"start\" x=\"195\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.665</text>\n<text text-anchor=\"start\" x=\"185.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n<text text-anchor=\"start\" x=\"172.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [33, 31, 36]</text>\n<text text-anchor=\"start\" x=\"182\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M200,-417.5C200,-417.5 107,-417.5 107,-417.5 101,-417.5 95,-411.5 95,-405.5 95,-405.5 95,-361.5 95,-361.5 95,-355.5 101,-349.5 107,-349.5 107,-349.5 200,-349.5 200,-349.5 206,-349.5 212,-355.5 212,-361.5 212,-361.5 212,-405.5 212,-405.5 212,-411.5 206,-417.5 200,-417.5\"/>\n<text text-anchor=\"start\" x=\"125.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"112.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"103\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [33, 0, 0]</text>\n<text text-anchor=\"start\" x=\"110\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M203.79,-460.91C196.38,-449.65 188.33,-437.42 180.88,-426.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"183.75,-424.1 175.33,-417.67 177.9,-427.94 183.75,-424.1\"/>\n<text text-anchor=\"middle\" x=\"170.28\" y=\"-438.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#eee4fb\" stroke=\"black\" d=\"M372.5,-425C372.5,-425 242.5,-425 242.5,-425 236.5,-425 230.5,-419 230.5,-413 230.5,-413 230.5,-354 230.5,-354 230.5,-348 236.5,-342 242.5,-342 242.5,-342 372.5,-342 372.5,-342 378.5,-342 384.5,-348 384.5,-354 384.5,-354 384.5,-413 384.5,-413 384.5,-419 378.5,-425 372.5,-425\"/>\n<text text-anchor=\"start\" x=\"238.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.65</text>\n<text text-anchor=\"start\" x=\"272\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.497</text>\n<text text-anchor=\"start\" x=\"266.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 67</text>\n<text text-anchor=\"start\" x=\"253\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 31, 36]</text>\n<text text-anchor=\"start\" x=\"259\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M257.21,-460.91C263.01,-452.1 269.2,-442.7 275.18,-433.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"278.26,-435.3 280.83,-425.02 272.41,-431.45 278.26,-435.3\"/>\n<text text-anchor=\"middle\" x=\"285.88\" y=\"-445.81\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#4de88e\" stroke=\"black\" d=\"M284.5,-306C284.5,-306 156.5,-306 156.5,-306 150.5,-306 144.5,-300 144.5,-294 144.5,-294 144.5,-235 144.5,-235 144.5,-229 150.5,-223 156.5,-223 156.5,-223 284.5,-223 284.5,-223 290.5,-223 296.5,-229 296.5,-235 296.5,-235 296.5,-294 296.5,-294 296.5,-300 290.5,-306 284.5,-306\"/>\n<text text-anchor=\"start\" x=\"152.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 5.0</text>\n<text text-anchor=\"start\" x=\"185\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.165</text>\n<text text-anchor=\"start\" x=\"179.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"170\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 30, 3]</text>\n<text text-anchor=\"start\" x=\"168\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M277.32,-341.91C270.64,-332.92 263.49,-323.32 256.6,-314.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"259.41,-311.96 250.63,-306.02 253.79,-316.13 259.41,-311.96\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#853fe6\" stroke=\"black\" d=\"M462,-306C462,-306 327,-306 327,-306 321,-306 315,-300 315,-294 315,-294 315,-235 315,-235 315,-229 321,-223 327,-223 327,-223 462,-223 462,-223 468,-223 474,-229 474,-235 474,-235 474,-294 474,-294 474,-300 468,-306 462,-306\"/>\n<text text-anchor=\"start\" x=\"323\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.85</text>\n<text text-anchor=\"start\" x=\"359\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.057</text>\n<text text-anchor=\"start\" x=\"353.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n<text text-anchor=\"start\" x=\"344\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 33]</text>\n<text text-anchor=\"start\" x=\"346\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M337.68,-341.91C344.36,-332.92 351.51,-323.32 358.4,-314.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"361.21,-316.13 364.37,-306.02 355.59,-311.96 361.21,-316.13\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M109,-179.5C109,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 109,-111.5 109,-111.5 115,-111.5 121,-117.5 121,-123.5 121,-123.5 121,-167.5 121,-167.5 121,-173.5 115,-179.5 109,-179.5\"/>\n<text text-anchor=\"start\" x=\"32.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"19.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"10\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 29, 0]</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M164.99,-222.91C148.54,-210.88 130.56,-197.73 114.23,-185.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.99,-182.74 105.86,-179.67 111.86,-188.39 115.99,-182.74\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#ab7bee\" stroke=\"black\" d=\"M289.5,-187C289.5,-187 151.5,-187 151.5,-187 145.5,-187 139.5,-181 139.5,-175 139.5,-175 139.5,-116 139.5,-116 139.5,-110 145.5,-104 151.5,-104 151.5,-104 289.5,-104 289.5,-104 295.5,-104 301.5,-110 301.5,-116 301.5,-116 301.5,-175 301.5,-175 301.5,-181 295.5,-187 289.5,-187\"/>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 6.05</text>\n<text text-anchor=\"start\" x=\"185\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"183\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"173.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 3]</text>\n<text text-anchor=\"start\" x=\"172\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M220.5,-222.91C220.5,-214.65 220.5,-205.86 220.5,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"224,-197.02 220.5,-187.02 217,-197.02 224,-197.02\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M145,-68C145,-68 48,-68 48,-68 42,-68 36,-62 36,-56 36,-56 36,-12 36,-12 36,-6 42,0 48,0 48,0 145,0 145,0 151,0 157,-6 157,-12 157,-12 157,-56 157,-56 157,-62 151,-68 145,-68\"/>\n<text text-anchor=\"start\" x=\"68.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"59\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"49.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\n<text text-anchor=\"start\" x=\"44\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M174.33,-103.73C163.69,-94.33 152.38,-84.35 141.78,-74.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"144.02,-72.3 134.21,-68.3 139.39,-77.54 144.02,-72.3\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M276,-68C276,-68 187,-68 187,-68 181,-68 175,-62 175,-56 175,-56 175,-12 175,-12 175,-6 181,0 187,0 187,0 276,0 276,0 282,0 288,-6 288,-12 288,-12 288,-56 288,-56 288,-62 282,-68 276,-68\"/>\n<text text-anchor=\"start\" x=\"203.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"194\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"184.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\n<text text-anchor=\"start\" x=\"183\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.6,-103.73C225.43,-95.43 226.31,-86.67 227.15,-78.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"230.64,-78.6 228.15,-68.3 223.67,-77.9 230.64,-78.6\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#ab7bee\" stroke=\"black\" d=\"M457,-187C457,-187 332,-187 332,-187 326,-187 320,-181 320,-175 320,-175 320,-116 320,-116 320,-110 326,-104 332,-104 332,-104 457,-104 457,-104 463,-104 469,-110 469,-116 469,-116 469,-175 469,-175 469,-181 463,-187 457,-187\"/>\n<text text-anchor=\"start\" x=\"328\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal width (cm) ≤ 3.1</text>\n<text text-anchor=\"start\" x=\"359\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"357\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"347.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 3]</text>\n<text text-anchor=\"start\" x=\"346\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M394.5,-222.91C394.5,-214.65 394.5,-205.86 394.5,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"398,-197.02 394.5,-187.02 391,-197.02 398,-197.02\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M592,-179.5C592,-179.5 499,-179.5 499,-179.5 493,-179.5 487,-173.5 487,-167.5 487,-167.5 487,-123.5 487,-123.5 487,-117.5 493,-111.5 499,-111.5 499,-111.5 592,-111.5 592,-111.5 598,-111.5 604,-117.5 604,-123.5 604,-123.5 604,-167.5 604,-167.5 604,-173.5 598,-179.5 592,-179.5\"/>\n<text text-anchor=\"start\" x=\"517.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"504.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"start\" x=\"495\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 30]</text>\n<text text-anchor=\"start\" x=\"497\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M446.89,-222.91C462.27,-210.99 479.07,-197.98 494.37,-186.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"496.93,-188.56 502.69,-179.67 492.65,-183.03 496.93,-188.56\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M428,-68C428,-68 339,-68 339,-68 333,-68 327,-62 327,-56 327,-56 327,-12 327,-12 327,-6 333,0 339,0 339,0 428,0 428,0 434,0 440,-6 440,-12 440,-12 440,-56 440,-56 440,-62 434,-68 428,-68\"/>\n<text text-anchor=\"start\" x=\"355.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"346\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"336.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\n<text text-anchor=\"start\" x=\"335\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M390.4,-103.73C389.57,-95.43 388.69,-86.67 387.85,-78.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"391.33,-77.9 386.85,-68.3 384.36,-78.6 391.33,-77.9\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M567,-68C567,-68 470,-68 470,-68 464,-68 458,-62 458,-56 458,-56 458,-12 458,-12 458,-6 464,0 470,0 470,0 567,0 567,0 573,0 579,-6 579,-12 579,-12 579,-56 579,-56 579,-62 573,-68 567,-68\"/>\n<text text-anchor=\"start\" x=\"490.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"481\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"471.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\n<text text-anchor=\"start\" x=\"466\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M440.67,-103.73C451.31,-94.33 462.62,-84.35 473.22,-74.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"475.61,-77.54 480.79,-68.3 470.98,-72.3 475.61,-77.54\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7e7c2305c410>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#21 Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "data = load_wine()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.20, random_state= 1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Decision Tree with max_depth=3\n",
        "dt_with_depth = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
        "dt_with_depth.fit(x_train,y_train)\n",
        "\n",
        "y_pred_with_max = dt_with_depth.predict(x_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_with_max)\n",
        "print(\"Accuracy With Max Depth Of 3 :\", accuracy)\n",
        "\n",
        "\n",
        "# Fully grown Decision Tree (no depth restriction)\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train,y_train)\n",
        "\n",
        "y_pred = dt.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('\\n')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpqt-RyvVql4",
        "outputId": "9f3dc406-fc46-42af-d86f-fe9e2a16fe3e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy With Max Depth Of 3 : 0.8611111111111112\n",
            "\n",
            "\n",
            "Accuracy: 0.8888888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22 Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its accuracy with a default tree.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "data = load_wine()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.20, random_state= 1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Decision Tree with min_samples_split=5 (controls splitting behavior)\n",
        "dt_with_min = DecisionTreeClassifier(min_samples_split= 5, random_state=1)\n",
        "dt_with_min.fit(x_train,y_train)\n",
        "\n",
        "y_pred_with_min = dt_with_min.predict(x_test)\n",
        "\n",
        "\n",
        "# Fully grown Decision Tree (no depth restriction)\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train,y_train)\n",
        "\n",
        "y_pred = dt.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "# Compare accuracies\n",
        "print(\"\\nComparison:\")\n",
        "accuracy = accuracy_score(y_test, y_pred_with_min)\n",
        "print(\"Accuracy (min_samples_split=5):\", accuracy)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nAccuracy (Default Tree):\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubd17yZuYO7M",
        "outputId": "a839cebe-d94d-471f-d6c8-ac9c11e71d26"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison:\n",
            "Accuracy (min_samples_split=5): 0.8611111111111112\n",
            "\n",
            "Accuracy (Default Tree): 0.8888888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23 Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its accuracy with unscaled data.\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "data = load_wine()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.30, random_state= 1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Decision Tree with Scaled\n",
        "dt_with_scaled = DecisionTreeClassifier()\n",
        "dt_with_scaled.fit(x_train_scaled , y_train)\n",
        "\n",
        "y_pred_scaled = dt_with_scaled.predict(x_test_scaled)\n",
        "\n",
        "\n",
        "# Decision Tree without scaled\n",
        "dt_without_scaled = DecisionTreeClassifier()\n",
        "dt_without_scaled.fit(x_train,y_train)\n",
        "\n",
        "y_pred_without_scaled = dt_without_scaled.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "# Compare accuracies\n",
        "print(\"\\nComparison:\")\n",
        "accuracy = accuracy_score(y_test, y_pred_scaled)\n",
        "print(\"Accuracy with scaled:\", accuracy)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_without_scaled)\n",
        "print(\"\\nAccuracy without scaled:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU1gjhbMaIdh",
        "outputId": "12041f95-e89c-4268-a59e-358f82b750e4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison:\n",
            "Accuracy with scaled: 0.9629629629629629\n",
            "\n",
            "Accuracy without scaled: 0.9629629629629629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24 Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification.\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.33, random_state= 1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "ovr_classifier = OneVsRestClassifier(dt)\n",
        "ovr_classifier.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = ovr_classifier.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the One-vs-Rest Decision Tree Classifier: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J_awh18eEgB",
        "outputId": "21952111-d1af-4bdd-befd-3350265cb90e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the One-vs-Rest Decision Tree Classifier: 96.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25 Write a Python program to train a Decision Tree Classifier and display the feature importance scores.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "data = load_wine()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.33, random_state= 1)\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "\n",
        "for feature , important in zip(data.feature_names, model.feature_importances_):\n",
        "  print(f\"{feature} : {important}\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9fI6EPXfbWO",
        "outputId": "44bdf230-7c40-4484-dba3-b62925875ba1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alcohol : 0.024531353894941408\n",
            "\n",
            "malic_acid : 0.005858395989974966\n",
            "\n",
            "ash : 0.0\n",
            "\n",
            "alcalinity_of_ash : 0.0\n",
            "\n",
            "magnesium : 0.019172932330827067\n",
            "\n",
            "total_phenols : 0.0\n",
            "\n",
            "flavanoids : 0.36878617308298073\n",
            "\n",
            "nonflavanoid_phenols : 0.0\n",
            "\n",
            "proanthocyanins : 0.0\n",
            "\n",
            "color_intensity : 0.0\n",
            "\n",
            "hue : 0.03651987110633727\n",
            "\n",
            "od280/od315_of_diluted_wines : 0.10218828687644167\n",
            "\n",
            "proline : 0.442942986718497\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26 Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree.\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "data = load_diabetes()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.20, random_state= 1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Decision Tree with max_depth=5\n",
        "dt_depth_5 = DecisionTreeRegressor(max_depth=5, random_state=1)\n",
        "dt_depth_5.fit(x_train, y_train)\n",
        "y_pred_depth_5 = dt_depth_5.predict(x_test)\n",
        "mse_depth_5 = mean_squared_error(y_test, y_pred_depth_5)\n",
        "\n",
        "# Fully grown Decision Tree\n",
        "dt_full = DecisionTreeRegressor(random_state=1)\n",
        "dt_full.fit(x_train, y_train)\n",
        "y_pred_full = dt_full.predict(x_test)\n",
        "mse_full = mean_squared_error(y_test, y_pred_full)\n",
        "\n",
        "# Compare performance\n",
        "print(\"\\nComparison:\")\n",
        "print(f\"MSE (max_depth=5): {mse_depth_5:.2f}\")\n",
        "print(f\"MSE (unrestricted tree): {mse_full:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1NQ_zAXh7Hh",
        "outputId": "65591f64-2d9e-4724-f384-298448f32853"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison:\n",
            "MSE (max_depth=5): 5396.27\n",
            "MSE (unrestricted tree): 6703.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27 Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and visualize its effect on accuracy.\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.20, random_state= 1)\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train, y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Get pruning path\n",
        "path = dt.cost_complexity_pruning_path(x_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "\n",
        "# Store accuracies\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Test different pruning levels\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    pruned_dt = DecisionTreeClassifier(random_state=1, ccp_alpha=ccp_alpha)\n",
        "    pruned_dt.fit(x_train, y_train)\n",
        "\n",
        "    train_accuracies.append(accuracy_score(y_train, pruned_dt.predict(x_train)))\n",
        "    test_accuracies.append(accuracy_score(y_test, pruned_dt.predict(x_test)))\n",
        "\n",
        "# Find optimal alpha (max test accuracy)\n",
        "optimal_alpha = ccp_alphas[np.argmax(test_accuracies)]\n",
        "print(f\"Optimal CCP Alpha: {optimal_alpha:.5f}\")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(ccp_alphas, train_accuracies, 'o-', label=\"Training Accuracy\")\n",
        "plt.plot(ccp_alphas, test_accuracies, 'o-', label=\"Test Accuracy\")\n",
        "plt.axvline(optimal_alpha, color='red', linestyle='--',\n",
        "            label=f'Optimal Alpha: {optimal_alpha:.5f}')\n",
        "plt.xlabel(\"CCP Alpha\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Effect of Cost Complexity Pruning on Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "CyhQk8YHkl3-",
        "outputId": "9c33110a-5b45-49f5-e58e-bfdfebee2861"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal CCP Alpha: 0.00437\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28 Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "data = load_wine()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.30, random_state= 1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkWs0hSimllO",
        "outputId": "3fc0675d-5ec2-45a1-9028-a862ff6275fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9644\n",
            "Recall: 0.9630\n",
            "F1-Score: 0.9631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29 Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.20, random_state= 1)\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "corr = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(corr, annot= True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Decision Tree Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "ts_xeOZgtUjJ",
        "outputId": "52973177-a513-428e-c960-c0a14c477903"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30 Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values for max_depth and min_samples_split.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "\n",
        "x = df\n",
        "y = data.target\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.20, random_state= 1)\n",
        "\n",
        "# Initialize the DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10, None],  # Experiment with different max depths\n",
        "    'min_samples_split': [2, 5, 10]   # Experiment with different min_samples_split values\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = best_model.predict(x_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1LW9PTVG20T",
        "outputId": "9e7c94bc-0860-4291-b9c2-0698923e3a57"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 5, 'min_samples_split': 2}\n"
          ]
        }
      ]
    }
  ]
}